# config/config.yaml

# === Model Configuration ===
model:
  d_model: 4096               # Dimension of token embeddings from VLM2Vec (4096 for LLaVA/VLM2Vec, 768 for CLIP)
  n_topics: 50                # Number of topics
  transformer_layers: 2       # Layers in the importance network transformer
  transformer_heads: 8        # Attention heads in transformer
  dropout: 0.1                # Dropout for encoder and importance net

# === Loss Weights ===
loss:
  lambda_entropy: 0.01        # Entropy regularization weight
  lambda_kl: 0.1              # KL divergence regularization weight

# === Optimizer & Scheduler ===
optimizer:
  name: adamw
  lr: 5e-5
  weight_decay: 0.01

scheduler:
  name: linear
  warmup_steps: 500

# === Training Configuration ===
training:
  batch_size: 4
  num_epochs: 20
  eval_every: 100
  save_every: 1
  gradient_clip: 1.0
  device: cuda

# === Data Configuration ===
data:
  name: "mscoco14"              # Dataset name (one of: wikiweb2m, spiqa, tqa, fhm, mscoco14, t4sa, vist)
  dataset_path: ./data/corpus/
  max_text_length: 512
  image_size: 224
  vocab_size: 2000             # Maximum vocabulary size
  min_word_freq: 5              # Minimum word frequency to include in vocabulary (filters rare words)
  embedding_path: ./data/embeddings/glove.6B.300d.txt  # For WE metric evaluation
  lazy_loading: true            # If true, use lazy loading to avoid memory overflow with large datasets

# === Pretrained Models ===
vlm2vec:
  model_name: "TIGER-Lab/VLM2Vec-LLaVa-Next"  # Default: VLM2Vec-LLaVA (4096-dim)
  # Options:
  # - "TIGER-Lab/VLM2Vec-LLaVa-Next" → 4096 dimensions (recommended)
  # - "llava-hf/llava-1.5-7b-hf" → 4096 dimensions  
  # - "llava-hf/llava-v1.6-mistral-7b-hf" → 4096 dimensions
  # - "openai/clip-vit-large-patch14" → 768 dimensions (set d_model: 768)
  pretrained_path: ./checkpoints/vlm2vec_llava_next.pth
  freeze: false

# === Output & Logging ===
output:
  save_dir: ./outputs/
  log_dir: ./logs/
  checkpoint_name: cemtm_model.pth
  wandb_project: cemtm-project

seed: 42
